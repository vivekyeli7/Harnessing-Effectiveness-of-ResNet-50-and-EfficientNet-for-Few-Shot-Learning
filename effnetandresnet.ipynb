{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyAzREvXl-QK",
        "outputId": "7fcbfa33-5e54-49af-9f12-6919cba6e964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import Libraries\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Step 2: Dataset Preparation with Augmentation\n",
        "data_dir = \"/content/drive/MyDrive/flowers\"\n",
        "\n",
        "# Data augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(20),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load dataset\n",
        "dataset = torchvision.datasets.ImageFolder(data_dir, transform=transform)\n",
        "num_classes = len(dataset.classes)\n",
        "\n",
        "# Step 3: Define Models\n",
        "def build_model(model_name):\n",
        "    if model_name == \"efficientnet\":\n",
        "        model = models.efficientnet_b0(pretrained=True)\n",
        "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    elif model_name == \"resnet50\":\n",
        "        model = models.resnet50(pretrained=True)\n",
        "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name.\")\n",
        "\n",
        "    # Gradually unfreeze layers\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    # Unfreeze the last 2 blocks\n",
        "    if model_name == \"efficientnet\":\n",
        "        for param in model.features[-2:].parameters():\n",
        "            param.requires_grad = True\n",
        "    else:\n",
        "        for param in model.layer4.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    return model\n",
        "\n",
        "# Step 4: Few-Shot Training and Evaluation with Cross-Validation\n",
        "def train_and_evaluate_with_kfold(model_name, dataset, k=5, epochs=10):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "    fold_accuracies = []\n",
        "\n",
        "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
        "        print(f\"\\n--- Fold {fold + 1}/{k} ---\")\n",
        "        train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
        "        val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
        "        train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
        "\n",
        "        model = build_model(model_name).to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            for images, labels in train_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            scheduler.step()\n",
        "            print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        accuracy = correct / total\n",
        "        fold_accuracies.append(accuracy)\n",
        "        print(f\"Fold {fold + 1} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    avg_accuracy = sum(fold_accuracies) / k\n",
        "    print(f\"\\nAverage Accuracy for {model_name}: {avg_accuracy:.4f}\")\n",
        "    return avg_accuracy\n",
        "\n",
        "# Step 5: Compare Models\n",
        "efficientnet_accuracy = train_and_evaluate_with_kfold(\"efficientnet\", dataset)\n",
        "resnet50_accuracy = train_and_evaluate_with_kfold(\"resnet50\", dataset)\n",
        "\n",
        "# Step 6: Print Final Results\n",
        "print(f\"\\nFinal Comparison:\\nEfficientNet Accuracy: {efficientnet_accuracy:.4f}\\nResNet-50 Accuracy: {resnet50_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip6NVL7Wh4_P",
        "outputId": "9df2645d-d519-4dc3-daff-19d49c849294"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Fold 1/5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 64.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.4008\n",
            "Epoch [2/10], Loss: 0.8248\n",
            "Epoch [3/10], Loss: 0.6176\n",
            "Epoch [4/10], Loss: 0.4265\n",
            "Epoch [5/10], Loss: 0.4537\n",
            "Epoch [6/10], Loss: 0.5441\n",
            "Epoch [7/10], Loss: 0.5149\n",
            "Epoch [8/10], Loss: 0.3978\n",
            "Epoch [9/10], Loss: 0.4221\n",
            "Epoch [10/10], Loss: 0.3270\n",
            "Fold 1 Accuracy: 0.7778\n",
            "\n",
            "--- Fold 2/5 ---\n",
            "Epoch [1/10], Loss: 1.4897\n",
            "Epoch [2/10], Loss: 0.9516\n",
            "Epoch [3/10], Loss: 0.6848\n",
            "Epoch [4/10], Loss: 0.5491\n",
            "Epoch [5/10], Loss: 0.4977\n",
            "Epoch [6/10], Loss: 0.4824\n",
            "Epoch [7/10], Loss: 0.3607\n",
            "Epoch [8/10], Loss: 0.3815\n",
            "Epoch [9/10], Loss: 0.3188\n",
            "Epoch [10/10], Loss: 0.2943\n",
            "Fold 2 Accuracy: 0.7222\n",
            "\n",
            "--- Fold 3/5 ---\n",
            "Epoch [1/10], Loss: 1.4775\n",
            "Epoch [2/10], Loss: 0.9514\n",
            "Epoch [3/10], Loss: 0.6358\n",
            "Epoch [4/10], Loss: 0.5880\n",
            "Epoch [5/10], Loss: 0.6091\n",
            "Epoch [6/10], Loss: 0.4431\n",
            "Epoch [7/10], Loss: 0.3911\n",
            "Epoch [8/10], Loss: 0.4334\n",
            "Epoch [9/10], Loss: 0.3783\n",
            "Epoch [10/10], Loss: 0.3627\n",
            "Fold 3 Accuracy: 0.7778\n",
            "\n",
            "--- Fold 4/5 ---\n",
            "Epoch [1/10], Loss: 1.4923\n",
            "Epoch [2/10], Loss: 0.8972\n",
            "Epoch [3/10], Loss: 0.6228\n",
            "Epoch [4/10], Loss: 0.4946\n",
            "Epoch [5/10], Loss: 0.5039\n",
            "Epoch [6/10], Loss: 0.5032\n",
            "Epoch [7/10], Loss: 0.4025\n",
            "Epoch [8/10], Loss: 0.3596\n",
            "Epoch [9/10], Loss: 0.3073\n",
            "Epoch [10/10], Loss: 0.4825\n",
            "Fold 4 Accuracy: 0.8333\n",
            "\n",
            "--- Fold 5/5 ---\n",
            "Epoch [1/10], Loss: 1.4471\n",
            "Epoch [2/10], Loss: 0.8846\n",
            "Epoch [3/10], Loss: 0.5855\n",
            "Epoch [4/10], Loss: 0.4760\n",
            "Epoch [5/10], Loss: 0.4912\n",
            "Epoch [6/10], Loss: 0.3431\n",
            "Epoch [7/10], Loss: 0.3459\n",
            "Epoch [8/10], Loss: 0.4248\n",
            "Epoch [9/10], Loss: 0.3347\n",
            "Epoch [10/10], Loss: 0.3204\n",
            "Fold 5 Accuracy: 0.7778\n",
            "\n",
            "Average Accuracy for efficientnet: 0.7778\n",
            "\n",
            "--- Fold 1/5 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.2929\n",
            "Epoch [2/10], Loss: 0.9470\n",
            "Epoch [3/10], Loss: 1.1462\n",
            "Epoch [4/10], Loss: 0.5928\n",
            "Epoch [5/10], Loss: 0.5123\n",
            "Epoch [6/10], Loss: 0.4440\n",
            "Epoch [7/10], Loss: 0.3453\n",
            "Epoch [8/10], Loss: 0.3113\n",
            "Epoch [9/10], Loss: 0.2603\n",
            "Epoch [10/10], Loss: 0.3780\n",
            "Fold 1 Accuracy: 0.5000\n",
            "\n",
            "--- Fold 2/5 ---\n",
            "Epoch [1/10], Loss: 1.4009\n",
            "Epoch [2/10], Loss: 1.0556\n",
            "Epoch [3/10], Loss: 1.0487\n",
            "Epoch [4/10], Loss: 0.7745\n",
            "Epoch [5/10], Loss: 0.4711\n",
            "Epoch [6/10], Loss: 0.5529\n",
            "Epoch [7/10], Loss: 0.3793\n",
            "Epoch [8/10], Loss: 0.3841\n",
            "Epoch [9/10], Loss: 0.3695\n",
            "Epoch [10/10], Loss: 0.3309\n",
            "Fold 2 Accuracy: 0.6667\n",
            "\n",
            "--- Fold 3/5 ---\n",
            "Epoch [1/10], Loss: 1.4981\n",
            "Epoch [2/10], Loss: 1.1678\n",
            "Epoch [3/10], Loss: 0.6146\n",
            "Epoch [4/10], Loss: 0.7081\n",
            "Epoch [5/10], Loss: 0.6016\n",
            "Epoch [6/10], Loss: 0.4933\n",
            "Epoch [7/10], Loss: 0.2276\n",
            "Epoch [8/10], Loss: 0.1908\n",
            "Epoch [9/10], Loss: 0.2656\n",
            "Epoch [10/10], Loss: 0.2068\n",
            "Fold 3 Accuracy: 0.8333\n",
            "\n",
            "--- Fold 4/5 ---\n",
            "Epoch [1/10], Loss: 1.4364\n",
            "Epoch [2/10], Loss: 1.2942\n",
            "Epoch [3/10], Loss: 1.0156\n",
            "Epoch [4/10], Loss: 0.8321\n",
            "Epoch [5/10], Loss: 0.5671\n",
            "Epoch [6/10], Loss: 0.6595\n",
            "Epoch [7/10], Loss: 0.5966\n",
            "Epoch [8/10], Loss: 0.7156\n",
            "Epoch [9/10], Loss: 0.4843\n",
            "Epoch [10/10], Loss: 0.5008\n",
            "Fold 4 Accuracy: 0.7222\n",
            "\n",
            "--- Fold 5/5 ---\n",
            "Epoch [1/10], Loss: 1.4503\n",
            "Epoch [2/10], Loss: 1.0798\n",
            "Epoch [3/10], Loss: 0.6622\n",
            "Epoch [4/10], Loss: 0.5913\n",
            "Epoch [5/10], Loss: 0.4825\n",
            "Epoch [6/10], Loss: 0.6112\n",
            "Epoch [7/10], Loss: 0.3928\n",
            "Epoch [8/10], Loss: 0.3761\n",
            "Epoch [9/10], Loss: 0.1387\n",
            "Epoch [10/10], Loss: 0.2227\n",
            "Fold 5 Accuracy: 0.8889\n",
            "\n",
            "Average Accuracy for resnet50: 0.7222\n",
            "\n",
            "Final Comparison:\n",
            "EfficientNet Accuracy: 0.7778\n",
            "ResNet-50 Accuracy: 0.7222\n"
          ]
        }
      ]
    }
  ]
}